# AttentionNotes.github.io

THESE are my personal notes that i made to understand attention based models, SELF attention and Transformsers 
please take a look and if you find something incorrect let me know, all source documents are referenced so please do check them out also. 

this is not all you need to understand these difficult concepts these are just my notes, please look at all the source documents

TODO : make the page easer to read and view

https://deeprajbasu.github.io/AttentionNotes.github.io/
