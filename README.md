# AttentionNotes.github.io

THESE are my personal notes that i made to understand attention based models, SELF attention and Transformsers 
please take a look and if you find something incorrect let me know, all source documents are referenced so please do check them out also. 

TODO : make the page easer to read and view

https://deeprajbasu.github.io/AttentionNotes.github.io/
